## 4장   처리율 제한 장치의 설계   

처리율 제한 장치는 클라이언트 또는 서비스가 보재는 트래픽의 처리율을 제어하기 위한 장치이다.  
특정 기간 내 전송되는 클라이언트의 요청 횟수를 제한한다.  
API 요청 횟수가 제한 장치에 정의된 임계치를 넘어서면 추가로 도달한 모든 호출은 처리가 중단된다.  


이 장치를 두면 좋은 점
1. DoS 공격에 의한 자원 고갈을 방지할 수 있다.  
2. 비용을 절감한다.  
3. 서버 과부하를 막는다.  

<br/>

### 1. 문제 이해 및 설계 범위 확정 
질문을 통해 요구사항을 파악하자!  
* 책에 나온 요구사항    
: 설정된 처리율을 초과하는 요청은 정확하게 제한한다.  
: 낮은 응답 시간  
: 가능한 적은 메모리를 사용해야 한다.  
: 예외 처리  
: 분산형 처리율 제한    
: 높은 결함 감내성   


### 2. 개략적 설계안 제시 및 동의 구하기  
기본적인 클라이언트-서버 통신 모델을 사용하도록 하자!  

**처리율 제한 장치는 어디에 둘까?**  

1. 클라이언트 측에 둔다면   
: 안정적으로 걸 수 있는 장소가 안된다.  
: 모든 클라이언트의 구현을 통제하는 것은 어려울 수 있다.  

2. 서버 측에 둔다면  
: API 서버에 두기  
**: 처리율 제한 미들웨어를 만들어 해당 미들웨어로 하여금 요청을 통제하기**  
-> 클라우드 마이크로서비스의 경우엔 이 장치를 보통 API 게이트웨이라고 불리는 컴포넌트에 구현된다.  


3. 그래서 어디에 두어야할까?  
: 정답은 없지만 기술 스택, 엔지니어링 인력, 우선순위, 목표에 따라 달라질 수 있다.  


**처리율 제한 알고리즘**  
이 알고리즘은 여러가지이며 각각의 장단점을 갖고 있다.  

1. 토큰 버킷  
이 알고리즘은 처리율 제한에 폭넓게 이용되고 있다.   
지정된 용량을 갖는 컨테이너로 버킷에는 사전 설정된 양의 토큰이 주기적으로 채워진다. 토큰 공급기는 이 버킷에 매초 2개의 토큰을 추가한다.
버킷이 가득 차면 추가로 공급된 버킷은 버려진다. (용량이 정해진 큐처럼 작동한다.)  

    구현이 쉽고 메모리 사용 측면에서 효율적이다. 짧은 시간에 집중되는 트래픽도 처리 가능하다.  
    버킷 크기와 토큰 공급률을 적절하게 튜닝하는 것이 어렵다. 


2. 누출 버킷 알고리즘  
토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있다는 점이 다르다. 이 알고리즘은 보통 FIFO 큐로 규현한다. 
요청이 도착하면 큐가 가득 차 있는지 본다. 빈자리가 있는 경우에는 큐에 요청을 추가한다. 큐가 가득 차 있는 경우에는 새 요청을 버린다. 저장된 시간마다 큐에서 요청을 꺼내서 처리한다.  
    큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적이다. 
    고정된 처리율을 갖고 있기에 안정적인 출력이 필요한 경우에 적합하다.  
    단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓여 제때 처리하지  못하면 최신 요청들은 버려진다.  
  

3. 고정 윈도 카운터 알고리즘  
타임라인을 고정된 간격의 윈도로 나누고 각 윈도마다 카운터를 붙인다. 요청이 접수될 때마다 이 카운터의 값은 1씩 증가한다.   
이 카운터의 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다.  

    메모리 효율이 좋다. 이해하기 쉽다. 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰리는 경우 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.  
  
  
4. 이동 윈도 로깅 알고리즘  
요청의 타임스탬프를 추적한다. 새 요청이 오면 만료된 타임 스탬프를 제거한다. 새 요청의 타임스탬프를 로그에 추가한다. 로그의 크기가 허용치보다 같거나 적으면 효청을 시스템에 전달한다. 그렇지 앟은 경우에는 처리를 거부한다.  
    구현하는 처리율 알고리즘이 아주 정교하다. 다량의 메모리를 사용한다.  
  

5. 이동 윈도 카운터 알고리즘 
고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 합친 것이다. 
    이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하여 ㅉ랍은 시간에 몰리는 트래픽에 잘 대응할 수 있다. 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기에 다소 느슨하다.  

<hr/>
   
**개략적인 아키텍쳐**

알고리즘은 얼마나 많은 요청이 접수되었는지 추적할 수 있는 카운터를 추적 대상별로 두고 카운터의 값이 어떤 한도를 넘으면 도착한 요청은 거부하는 것이다.  
이 카운터를 어디에 보관할까? 
메모리상에서 동작하는 캐시가 바람직하고 시간에 기반한 만료 정책을 지원해서 바람직하다.  
redis는 처리율 제한 장치를 구현할 대 자주 사용되는 메모리 기반 저장 장치로 INCR과 EXPIRE의 두 가지 명령어를 지원한다.  

  
### 3단계 상세 설계 

처리율 제한 규칙 - 리프트는 처리율 제한에 오픈소스를 사용하고 있다. 이런 규칙들은 모통 설정 파일 형태로 디스크에 저장된다.  

**처리율 한도 초과 트래픽 처리**  
- 요청이 한도 제한에 걸리면 api는 429 응답을 보낸다.  
- 경우에 따라서는 한도 제한에 걸린 메세지를 나중에 처리하기 위해 큐에 보관할 수 있다.  
- 요청이 처리율 제한에 걸리기까지 얼마나 많은 요청을 보낼 수 있는지 아는 방법은 HTTP 응답 헤더를 보면 된다.  

처리율에 있어 풀어야할 숙제
1. 경쟁 조건
2. 동기화 


1. 경쟁 조건  
경쟁 조건 문제의 해결책은 락이다.  
락은 시스템의 성능을 떨어뜨려 루아 스크립트, 정렬 집합이라 불리는 레디스 자료구조를 사용하는 것이 좋다.    
  

2. 동기화    
레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것이 좋다.  


### 4단계 마무리

경성 또는 연성 처리율 제한  
다양한 계층에서의 처리율 제한   
처리율 제한을 회피하는 방법    

