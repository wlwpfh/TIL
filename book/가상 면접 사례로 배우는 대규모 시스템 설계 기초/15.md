## 15장 구글 드라이브 설계  

### 1단계 문제 이해 및 설계 범위 확정  
- 집중할 기능
  - 파일 추가, 파일을 구글 드라이브 안으로 떨구는 것이다. (`drag-drop`)
  - 파일 다운로드
  - 여러 단말에 파일 동기화
  - 파일 갱신 이력 조회
  - 파일 공유
  - 파일이 편집 / 삭제 / 공유되었을 때 알림 표시
- 논의하지 않을 기능
  - 구글 문서 편집 및 협업 기능 
- 비-기능적 요구사항
  - 안정성
  - 빠른 동기화 속도 
  - 네트워크 대역폭
  - 구모 확장성
  - 높은 가용성 

**개략적 추정치**  
- 가입 사용자는 오천만명이고 천만명의 DAU가 있다.  
- 모든 사용자에게 10GB이 무료 저장공간 할당 
- 매일 각 사용자가 평균 2개의 파일을 업로드한다고 가정. (각 파일의 평균 크기는 500KB)
- 읽기와 쓰기의 비율은 1:1
- 필요한 저장공간 총량 = 5천만 사용자 * 10GB = 500테파바이트
- 업로드 API QPS = 1천만 사용자 * 2회 업로드 / 24시간 / 3600초 = 약 240
- 최대 QPS = QPS * 2= = 480

### 2단계 개략적 설계안 제시 및 동의 구하기  
모든 것을 담은 한 대의 서버에서 출발해 점진적으로 천만 사용자 지원이 가능한 시스템으로 발전시켜보자.   
- 한 대의 서버로 할 것  
1. 파일을 올리고 다운로드하는 과정을 처리할 웹 서버
2. 사용자 데이터, 로그인 정보, 파일 정보 등의 메타데이터를 보관할 데이터베이스  
3. 파일을 저장할 저장소 시스템, 파일 시스템, 파일 저장을 위해 1TB의 공간을 사용할 것  

**API**  
파일 업로드 API, 다운로드 API, 파일 갱신 히스토리 제공 API가 필요하다. 

1. 파일 업로드 API
- 단순 파일 업로드: 파일 크기가 작을 때 사용한다.  
  - 이어 올리기: 파일 사이즈가 크고 네트워크 문제로 업로드가 중단될 ㄷ가능성이 높다고 생각되면 사용한다.  
  `https://api-example.com/files/upload?uploadType=resumable`에서 `uploadType`은 `resumable`, `data`는 업로드할 로컬 파일  
    - 절차 : 이어 올리기 URL을 받기 위한 최초 요청 전송 - 데이터를 업로드하고 업로드 상태 모니터링 - 업로드에 장애가 발생하면 장애 발생시점부터 업로드를 재시작  

2. 파일 다운로드 API  
`https://api-example.com/files/download`  
인자: `path` 다운로드 할 파일의 경로

3. 파일 갱신 히스토리 API  
`https://api-example.com/files/list_revisions`    
인자: `path` 갱신 히스토리를 가져올 파일의 경로, `limit` 히스토리 길이의 최대치   

해당 API들은 모든 사용자 인증을 필요로 하고 HTTPS 프로토콜을 사용해야 한다. 
SSL을 지원하는 프로토콜을 이용하는 이유는 클라이언트와 백엔드 서버가 주고받는 데이터를 보호하기 위한 것이다.  


<hr/>

**한 대 서버의 제약 극복**  

파일이 많아지면 결국 파일 시스템은 가득차게 된다.  
이를 해결하기 위해서는 데이터를 샤딩하여 여러 서버에 나누어 저장하는 것이다.  

아마존 S3는 최고 수준의 성능을 제공하는 객체 저장소 서비스이다.  
S3는 다중화를 지원하는데, 같은 지역 안에서 다중화를 할 수도 있고, 여러 지역에 걸쳐 다중화를 할 수도 있다.  

AWS 서비스 지역은 아마존이 데이터 센터를 운영하는 지리적 영역이다.  

데이터를 다중화할 때에는 같은 지역안에서만 할 수도 있고 여러 지역에 걸쳐 할 수도 있다.  
여러 지역에 걸쳐 다중화하면 데이터 손실을 막고 가용성을 최대한 보장할 수 있다.  

- 더욱 개선해야 할 사항  
1. 로드밸런서: 트래픽을 분산하기 위해 로드밸런서를 사용한다.  
2. 웹 서버: 웹 서버를 쉽게 추가할 수 있다.  
3. 메타데이터 데이터베이스: 데이터베이스를 파일 저장 서버에서 분리하여 SPOF를 회피한다.  
4. 파일 저장소: S3를 파일 저장소로 사용하고 가용성과 데이터 무손실을 보장하기 위해 두 개 이상의 지역에 데이터를 다중화한다.  

**동기화 충돌**  
두 명 이상의 사용자가 같은 파일이나 폴더를 동시에 업데이트할 때 동기화 충돌이 발생할 수 있다.  
먼저 처리되는 변경을 성공으로, 나중에 처리되는 변경을 충돌이 발생하는 것으로 보면 된다.  

충돌이 발생한 오류는 어떻게 해결해야 할까?  
이 시점에는 해당 사용자가 가지고 있는 로컬 사본과 서버에 있는 최신 버전이 존재한다.  

이 상태에서 사용자는 두 파일을 하나로 합칠지 아니면 둘 주에 하나를 다른 파일로 대체할지 결정한다.  

**개략적 설계안**  
이제 각 컴포넌트에 대해 상세하게 알아보자!  

- 사용자 단말  
: 사용자가 이용하는 웹 브라우저나 모바일 앱 등의 클라이언트

- 블록 저장소 서버  
: 파일 블록을 클라우드 저장소에 업로드하는 서버다. 파일을 여러 개의 블록으로 나눠 저장하며, 각 블록에는 고유한 해시값이 할당된다. 
각 블록은 독립적은 객체로 취급되며 클라우드 저장소 시스템에 보관된다. 

- 클라우드 저장소  
: 파일을 블록 단위로 나눠져 클라우드 저장소에 보관된다.  

- 아카이빙 저장소  
: 오랫동안 사용되지 않은 비활성 데이터를 저장하기 위한 컴퓨터 시스템이다.  

- 로드밸런서  
: 요청을 모든 API 서버에 고르게 분산하는 구실을 한다.  

- API 서버   
: 파일 업로드 외에 거의 모든 것을 담당하는 서버이다.  

- 메타데이터 데이터베이스  
: 사용자, 파일, 블록, 버전 등의 메타데이터 정보를 관리한다.  

- 메타데이터 관리  
: 성능을 높이기 위해 자주 쓰이는 메타데이터는 캐시한다.  

- 알림 서비스   
: 특정 이벤트가 발생했음을 클라이언트에게 알리는데 쓰이는 발생/구독 프로토콜 기반의 시스템이다.  

- 오프라인 사용자 백업 큐  
: 클라이언트가 접속 중이 아니라서 파일의 최신 상태를 확인할 수 없을 때에 해당 정보를 이 큐에 두어 나중에 클라이언트가 접속했을 때 동기화될 수 있도록 한다.  

<hr/>

### 3단계 상세 설계  

**1. 블록 저장소 서버**  
정기적으로 갱신되는 큰 파일들의 업데이트가 일어날 때 전체 파일을 서버로 보내면 네트워크 대역폭을 많이 잡아먹게 된다.  
이를 최적화 하는 방법은 두 가지가 있다.  

- 델타 동기화: 파일이 수정되면 전체 파일 대신 수정이 일어난 블록만 동기화하는 것이다.  
- 압축: 블록 단위로 압축하면 데이터 크기를 많이 줄일 수 있다.  

블록 저장소 서버는 파일 업로드에 관계된 힘든 일을 처리하는 컴포넌트이다.  
파일을 블록 단위로 나누고, 각 블록에 압축 알고리즘을 적용하고, 암호화를 해야 한다.  

- 새 파일이 추가되었을 때  
: 주어진 파일을 작은 블록들로 분할한다 -> 각 블록을 압축한다 -> 클라우드 저장소로 보내기 전에 암호화한다 -> 클라우드 저장소로 보낸다.  

블록 저장소 서버에 델타 동기화 전력과 압축 알고리즘을 도입하여 네트워크 대역폭 사용량을 절감할 수 있다.  


**2. 높은 일관성 요구상황**  
강한 일관성을 유지해야한다.  같은 파일이 단말이나 사용자에 따라 다르게 보이는 것은 허용할 수 없다.  

메타데이터 캐시와 데이터베이스 계층에서도 같은 원칙이 적용되어야 한다.  

메모리 캐시는 보통 최종 일관성 모델을 지원한다. 
- 캐시에 보관된 사본과 데이터베이스에 있는 원본이 일치한다.  
- 데이터베이스에 보관된 원본에 변경이 발생하면 캐시에 있는 사본을 무효화한다.  

관계형 데이터베이스에서는 ACID를 보장하므로 강한 일관성을 보장하기 쉽다.  
NoSQL 데이터베이스는 이를 기본적으로 지원하지 않아 동기화 로직 안에 프로그램하여 넣어야 한다.  


**3. 메타데이터 데이터베이스**  
- user: 이름, 이메일, 프로파일 사진 등 사용자에 관계된 기본 정보들이 보관된다.  
- device: 단말 정보가 보관된다. 
- namespace: 사용자의 루트 디렉토리 정보가 보관된다.    
- file: 파일의 최신 정보를 보관한다.  
- file_version: 파일의 갱신 이력이 보관된다. 전부 읽기 전용이다.  
- block: 파일 블록에 대한 정보를 보관하는 테이블이다.  

**4. 업로드 절차**  
- 파일 메타 데이터 추가  
1. 클라이언트 1이 새 파일의 메타데이터를 추가하기 위한 요청 전송
2. 새 파일의 메타데이터를 데이터베이스에 저장하고 업로드 상태를 대기중으로 변경
3. 새 파일이 추가되었음을 알림 서비스에 통지  
4. 알림 서비스는 관련된 클라이언트에게 파일이 업로드되고 있음을 알림  

- 파일을 클라우드 저장소에 업로드  
1. 클라이언트1이 파일을 블록 저장소 서버에 업로드  
2. 블록 저장소 서버는 파일을 블록 단위로 쪼갠 다음 압축하고 암호화 한 다음에 클라우드 저장소에 전송  
3. 업로드가 끝나면 클라우드 스토리지는 완료 콜백을 호출한다.  이 콜백 호출은 API 서버로 전송됨  
4. 메타데이터 DB에 기록된 해당 파일의 상태를 완료로 변경  
5. 알림 서비스에 파일 업로드가 끝났음을 통지  
6. 알림 서비스는 관련된 클라이언트2에게 파일 업로드가 끝났음을 알림

**5. 다운로드 절차**
어떤 파일이 변경되었음을 감지한 클라이언트는 우선 API 서버를 통해 메타데이터를 새로 가져가야하고, 그 다음에 블록들을 다운받아 파일을 재구성해야 한다.  

1. 알림 서비스가 클라이언트2에게 누군가 파일을 변경했음을 알림
2. 알림을 확인한 클라이언트2는 새로운 메타데이터를 요청  
3. API 서버는 메타데이터 데이터베이스에게 새 메타데이터 요청  
4. API 서버에게 새 메타데이터가 반환됨
5. 클라이언트2에게 새 메타데이터가 반환됨
6. 클라이언트2는 새 메타데이터를 받는 즉시 블록 다운로드 요청 전송  
7. 블록 저장소 서버는 클라우드 저장소에서 블록 다운로드  
8. 클라우드 저장소는 블록 서버에 요청된 블록 반환 
9. 블록 저장소 서버는 클라이언트에게 요청된 블록 반환, 클라이언트2는 전송된 블록을 사용하여 파일 재구성

**6. 알림 서비스**  
파일의 일관성을 유지하기 위해, 클라이언트는 로컬에서 파일이 수정되었음을 감지하는 순간 다른 클라이언트에게 그 사실을 알려서 충돌 가능성을 줄어야 한다.  
알림 서비스는 단순하게 이벤트 데이터를 클라이언트들로 보내는 서비스이다.  

- 롱 폴링: 드롭박스가 이 방식을 채택하고 있다.  
- 웹소켓: 클라이언트와 서버 사이에 지속적인 통신 채널을 제공한다. 따라서 양방향 통신이 가능하다.  

롱 폴링을 이용할 예정이다.  
왜냐하면 양방향 통신이 굳이 필요하지 않다.   
롱 폴링 방안을 쓰면 각 클라이언트는 알림 서버와 롱 폴링용 연결을 유지하다가 특정 파일에 대한 변경을 감지하면 해당 연결을 끊는다.  

이 때 클라이언트는 반드시 메타데이터 서버와 연결해 파일의 최신 내역을 다운로드 해야 한다.  
즉시 새 요청을 보내 롱 폴링 연결을 복원하고 유지해야 한다.  

**7. 저장소 공간 절약**  

파일 갱신 이력을 보존하고 안정성을 보장하기 위해서는 파일의 여러 버전을 여러 데이터센터에 보관할 필요가 있다.  
이런 문제를 해결하고 비용을 절감하기 위한 방법이 있다.  

1. 중복 제거: 중복된 파일 블록을 계정 차원에서 제거하는 방법이다. 해시값을 비교하여 판단한다.  
2. 지능적 백업 전략을 도입한다.  
   1. 한도설정: 보관해야 하는 파일 버전 개수에 상한을 두는 것이다.  
   2. 중요한 버전 보관: 불필요한 버전과 사본이 만들어지는 것을 피하려면 가운데 중요한 것만 골라내야 한다.
3. 자주 쓰이지 않는 데이터는 아카이빙 저장소로 옮긴다. 

**8. 장애 처리**  
1. 로드밸런서 장애: 부 로드밸런서가 활성화되어 트래픽을 이어받아야 한다. 로드밸런서 끼리는 박동 신호를 주기적으로 보내서 상태를 모니터링한다. 
2. 블록 저장소 서버 장애: 다른 서버가 미완료 상태 또는 대기 상태인 작업을 이어받아야 한다. 
3. 클라우드 저장소 장애: S3 버킷은 여러 지역에 다중화할 수 있어 한 지역에서 장애가 발생하면 다른 지역에서 파일을 가져오면 된다.  
4. API 서버 장애: 로드 밸런서는 API 서버에 장애가 발생하면 트래픽을 해당 서버로 보내지 않음으로 장애 서버를 격리할 것이다.  
5. 메타데이터 캐시 장애: 메타데이터 캐시 서버도 다중화한다. 장애가 발생한 서버는 새 서버로 교체한다.  
6. 메타데이터 데이터베이스 장애
   1. 주 데이터베이스 서버 장애: 부 데이터베이스 서버 가운데 하나를 주 데이터베이스로 바꾸고, 부 데이터베이스 서버를 새로 하나 추가한다.   
   2. 부 데이터베이스 서버 장애: 다른 부 데이터베이스 서버가 읽기 연산을 처리하도록 하고 그동안 장애 서버는 새 것으로 교체한다.  
7. 알림 서비스 장애: 접속중인 모든 사용자는 알림 서버와 롱 폴링 연결을 하나씩 유지한다. 한 대 서버에 장애가 발생하면 백만명 이상의 사용자가 롱 폴링 연결을 다시 만들어야 한다.  
8. 오프라인 사용자 백업 큐 장애: 이 큐 또한 다중화해둬야 한다. 큐에 장애가 발생하면 구독 중인 클라이언트들은 백업 큐로 구독 관계를 재설정해야 한다.  

<hr/>

### 4단계 마무리  
파일의 메타데이터를 관리하는 부분과 파일 동기화를 처리하는 부분으로 나눌 수 있다.  
알림 서비스는 두 부분과 병존하는 중요한 컴포넌트이다.  
롱 폴링을 사용하여 클라이언트로 하여금 파일의 상태를 최신으로 유지할 수 있도록 한다.  

파일을 클라우드 저장소에 직접 업로드한다면  
1. 분할, 압축, 암호화 로직을 클라이언트에 두어야 하므로 플랫폼별로 따로 구현해야 한다. 
2. 클라이언트가 해킹 당할 가능성이 있어 암호화 로직을 클라이언트 안에 두는 것은 적절하지 않은 선택일 수 있다.  

